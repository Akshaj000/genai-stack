# LLM Stack

[![PyPI](https://img.shields.io/pypi/v/llmstack)](https://pypi.org/project/llmstack/)
[![Discord](https://dcbadge.vercel.app/api/server/4aWV7He2QU?style=flat)](https://discord.gg/4aWV7He2QU)
[![Twitter](https://img.shields.io/twitter/follow/aiplanet4all)](https://twitter.com/aiplanet4all)
[![Open in Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1R-vnA0X5gTo_era8YChOvhFMVTVu7K-8?usp=sharing)

LLM Stack is an end-to-end framework for the integration of LLMs into any application. It comes with everything you need for data extraction/loading, vector embeddings, vector stores, LLMs, model deployment and serving.

## Getting started on Colab

Try out a quick demo of LLM Stack on Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1R-vnA0X5gTo_era8YChOvhFMVTVu7K-8?usp=sharing)

## Quick install

```bash
pip install git+https://github.com/aiplanethub/llmstack.git
```

## Documentation

The documentation for LLM Stack can be found at [llmstack.aiplanet.com](https://llmstack.aiplanet.com).

## LLM Stack Workflow
![Copy of Copy of Dark AI Planet card (1280 × 720 px) (1920 × 900 px) (2160 × 900 px) (2160 × 1170 px) (3)](https://github.com/aiplanethub/llmstack/assets/96718666/2ecba830-aebb-4b97-9edf-1ca4bb0c1545)


## What is LLM Stack all about?

LLM Stack is an end-to-end framework designed to integrate large language models (LLMs) into applications seamlessly. The purpose is to bridge the gap between raw data and actionable insights or responses that applications can utilize, leveraging the power of LLMs.

## How can LLM Stack be helpful?

- Integration Ease: LLM Stack offers a unified structure that allows developers to incorporate large language models into their applications without having to start from scratch.
- Data Utilization: By converting raw data into vector embeddings, it ensures that the valuable information within your data is optimally used for generating insights.
- Enhanced Search: Using embeddings and retrieval mechanisms, it provides a way to search through vast datasets quickly and accurately.
- Consistency: By using an established framework like LLM Stack, developers can ensure that their implementation is consistent with best practices and is optimized for performance.

## Use Cases:

- AI-Powered Search Engine: Enhance search with context-aware results, moving beyond simple keyword matching.
- Knowledge Base Q&A: Provide direct, dynamic answers from databases, making data access swift and user-friendly.
- Sentiment Analysis: Analyze text sources to gauge public sentiment, offering businesses real-time feedback.
- Customer Support Chatbots: Enhance the operational efficiency of customer support teams with near accurate responses to support queries.
- Information Retrieval on Large Volumes of Documents: Quickly extract specific information or related documents from vast repositories, streamlining data management.

## Contribution guidelines

LLM Stack thrives in the rapidly evolving landscape of open-source projects. We wholeheartedly welcome contributions in various capacities, be it through innovative features, enhanced infrastructure, or refined documentation.

For a comprehensive guide on the contribution process, please click [here](https://app.gitbook.com/o/-Mg1afEUq3HypLm46Vbq/s/fWJ1RLdoXjMtPiYoXUMB/getting-started/installation).
